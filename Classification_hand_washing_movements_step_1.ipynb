{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92032425",
   "metadata": {},
   "source": [
    "# 1. Исходные данные: преобразование датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e636221d",
   "metadata": {},
   "source": [
    "1. Загрузка исходного видео/landmark-датасета.  \n",
    "\n",
    "- информация о датасете: https://www.mdpi.com/2306-5729/6/4/38\n",
    "- ссылка на датасет: https://zenodo.org/records/4537209\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a37f8bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "import math\n",
    "\n",
    "from typing import Tuple, Dict, Optional\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bfa3ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(root_dir):\n",
    "    # statistics.csv в корне папки содержит список всех видео и их принадлежность к DataSetX\n",
    "    statistics_path = os.path.join(root_dir, \"statistics.csv\")\n",
    "    \n",
    "    if not os.path.isfile(statistics_path):\n",
    "        raise FileNotFoundError(\"В корне DataSet не найден statistics.csv\")\n",
    "\n",
    "    statistics = pd.read_csv(statistics_path)\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    # filename из statistics.csv — имя файла .csv аннотаций\n",
    "    for _, row in tqdm(statistics.iterrows(), total=len(statistics)):\n",
    "        video_file = row[\"filename\"]                  # например \"2020-06-26_18-28-10_camera102.csv\"\n",
    "        ds_name = row[\"location\"]                     # DataSet1 ... DataSet11\n",
    "        ds_path = os.path.join(root_dir, ds_name)\n",
    "\n",
    "        ann_root = os.path.join(ds_path, \"Annotations\")\n",
    "        if not os.path.isdir(ann_root):\n",
    "            continue\n",
    "\n",
    "        # Нужно найти файл в каждом Annotator*\n",
    "        for annotator in os.listdir(ann_root):\n",
    "            ann_dir = os.path.join(ann_root, annotator)\n",
    "            if not os.path.isdir(ann_dir):\n",
    "                continue\n",
    "\n",
    "            ann_file_path = os.path.join(ann_dir, video_file)\n",
    "            if not os.path.isfile(ann_file_path):\n",
    "                continue\n",
    "\n",
    "            df = pd.read_csv(ann_file_path)\n",
    "\n",
    "            df[\"dataset\"] = ds_name\n",
    "            df[\"annotator\"] = annotator\n",
    "            df[\"video\"] = video_file\n",
    "\n",
    "            rows.append(df)\n",
    "\n",
    "    if not rows:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    return pd.concat(rows, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7668eac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка датасета из: d:\\0_moydadir\\MII_lab_10_train_model\\DatasSet_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3185/3185 [00:01<00:00, 2865.04it/s] \n"
     ]
    }
   ],
   "source": [
    "current_dir_code = os.getcwd()\n",
    "current_dir_project = os.path.dirname(current_dir_code) # Спускаемся на уровень вниз\n",
    "dataset_folder_path = os.path.join(current_dir_project, \"DataSet\")\n",
    "# dataset_folder_path = os.path.join(current_dir_project, \"DatasSet_test\")\n",
    "print(\"Загрузка датасета из:\", dataset_folder_path)\n",
    "df = load_dataset(dataset_folder_path)\n",
    "# df = df[:1000]  # Тестовое ограничение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1b8a824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружено аннотаций: 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_time</th>\n",
       "      <th>is_washing</th>\n",
       "      <th>movement_code</th>\n",
       "      <th>dataset</th>\n",
       "      <th>annotator</th>\n",
       "      <th>video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DataSet4</td>\n",
       "      <td>Annotator1</td>\n",
       "      <td>2020-06-26_21-26-56_camera104.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DataSet4</td>\n",
       "      <td>Annotator1</td>\n",
       "      <td>2020-06-26_21-26-56_camera104.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DataSet4</td>\n",
       "      <td>Annotator1</td>\n",
       "      <td>2020-06-26_21-26-56_camera104.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DataSet4</td>\n",
       "      <td>Annotator1</td>\n",
       "      <td>2020-06-26_21-26-56_camera104.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>133.333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DataSet4</td>\n",
       "      <td>Annotator1</td>\n",
       "      <td>2020-06-26_21-26-56_camera104.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frame_time  is_washing  movement_code   dataset   annotator  \\\n",
       "0       0.000           1              0  DataSet4  Annotator1   \n",
       "1      33.333           1              0  DataSet4  Annotator1   \n",
       "2      66.667           1              0  DataSet4  Annotator1   \n",
       "3     100.000           1              0  DataSet4  Annotator1   \n",
       "4     133.333           1              0  DataSet4  Annotator1   \n",
       "\n",
       "                               video  \n",
       "0  2020-06-26_21-26-56_camera104.csv  \n",
       "1  2020-06-26_21-26-56_camera104.csv  \n",
       "2  2020-06-26_21-26-56_camera104.csv  \n",
       "3  2020-06-26_21-26-56_camera104.csv  \n",
       "4  2020-06-26_21-26-56_camera104.csv  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Загружено аннотаций: {len(df)}\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8516bb",
   "metadata": {},
   "source": [
    "Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadf9798",
   "metadata": {},
   "source": [
    "2. Визуализация исходных данных:\n",
    "    - Распределение количества аннотаций по классам\n",
    "    - Видео с отметкой landmark-ов рук для проверки корректности извлечения точек.\n",
    "    - 3D scatter plot распределения 21 точек на руке (для правой и левой)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b2250b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {\n",
    "    1: \"Ладонь к ладони\",\n",
    "    2: \"Ладонь по тыльной стороне,\\nпереплетённые пальцы\",\n",
    "    3: \"Ладонь к ладони,\\nпереплетённые пальцы\",\n",
    "    4: \"Тыльные стороны пальцев\\nк ладони, сцепленные пальцы\",\n",
    "    5: \"Круговые движения\\nбольшого пальца\",\n",
    "    6: \"Подушечки пальцев\\nпо ладони\",\n",
    "    7: \"Выключение крана\\nбумажным полотенцем\",\n",
    "    0: \"Иное движение\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce153af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_distribution(data, title):\n",
    "    counts = data[\"movement_code\"].value_counts().sort_index()\n",
    "    labels = [class_map.get(int(c), f\"Класс {c}\") for c in counts.index]\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(labels, counts.values)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Класс движения\")\n",
    "    plt.ylabel(\"Количество аннотаций\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_class_distribution(df, \"Распределение аннотаций по классам: весь датасет\")\n",
    "\n",
    "if \"dataset\" in df.columns:\n",
    "    for ds in sorted(df[\"dataset\"].unique()):\n",
    "        subset = df[df[\"dataset\"] == ds]\n",
    "        plot_class_distribution(subset, f\"Распределение аннотаций по классам: {ds}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e6ba9b",
   "metadata": {},
   "source": [
    "Датасет содержит сильный дисбаланс классов. Иных движений в датасете очень много."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d308b738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "664"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int((df[\"movement_code\"] != 0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc3d504",
   "metadata": {},
   "source": [
    "Всего загружено аннотаций 9 240 046, из них 2 327 699 являются размеченными данными, все остальное класс 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e50ac4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Параметры текста --------------------\n",
    "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "FONT_SCALE = 0.5\n",
    "FONT_THICKNESS = 1\n",
    "FONT_COLOR = (0, 255, 0)\n",
    "\n",
    "LINE_HEIGHT = 22\n",
    "START_Y = 120\n",
    "X_POS = 10\n",
    "\n",
    "# -------------------- Классы --------------------\n",
    "class_map_cv2 = {\n",
    "    0: \"Other\",\n",
    "    1: \"Palm to palm\",\n",
    "    2: \"Palm over dorsum\",\n",
    "    3: \"Palm to palm, fingers interlaced\",\n",
    "    4: \"Backs of fingers to palm\",\n",
    "    5: \"Rotational thumb rubbing\",\n",
    "    6: \"Fingertips to palm\",\n",
    "    7: \"Turn off faucet\"\n",
    "}\n",
    "\n",
    "# -------------------- MediaPipe --------------------\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "\n",
    "def visualize_annotations(video_path, annotations_path, output_folder, class_map=None):\n",
    "    # ---------- Проверка путей ----------\n",
    "    if not os.path.isfile(video_path):\n",
    "        raise FileNotFoundError(f\"Видео не найдено: {video_path}\")\n",
    "    if not os.path.isdir(annotations_path):\n",
    "        raise FileNotFoundError(f\"Папка аннотаций не найдена: {annotations_path}\")\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # ---------- Видео ----------\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # ---------- Аннотации ----------\n",
    "    annotators = {}\n",
    "    video_base = os.path.splitext(os.path.basename(video_path))[0]\n",
    "\n",
    "    for annotator in os.listdir(annotations_path):\n",
    "        annotator_path = os.path.join(annotations_path, annotator)\n",
    "        if not os.path.isdir(annotator_path):\n",
    "            continue\n",
    "\n",
    "        matched_files = [\n",
    "            f for f in os.listdir(annotator_path)\n",
    "            if f.lower().endswith(\".csv\") and f.startswith(video_base)\n",
    "        ]\n",
    "        if not matched_files:\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(os.path.join(annotator_path, matched_files[0]))\n",
    "        if not {\"frame_time\", \"is_washing\", \"movement_code\"}.issubset(df.columns):\n",
    "            continue\n",
    "\n",
    "        df = df.sort_values(\"frame_time\")\n",
    "        annotators[annotator] = df[\"movement_code\"].tolist()\n",
    "\n",
    "    if not annotators:\n",
    "        raise RuntimeError(\"Не найдено корректных файлов аннотаций.\")\n",
    "\n",
    "    # ---------- Выходное видео ----------\n",
    "    output_path = os.path.join(\n",
    "        output_folder,\n",
    "        os.path.basename(video_path).replace(\".mp4\", \"_annotated.mp4\")\n",
    "    )\n",
    "\n",
    "    writer = cv2.VideoWriter(\n",
    "        output_path,\n",
    "        cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "        fps,\n",
    "        (frame_w, frame_h)\n",
    "    )\n",
    "\n",
    "    # ---------- MediaPipe Hands ----------\n",
    "    with mp_hands.Hands(\n",
    "        static_image_mode=False,\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5\n",
    "    ) as hands:\n",
    "\n",
    "        for i in range(total_frames):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # --- MediaPipe expects RGB ---\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            result = hands.process(rgb)\n",
    "\n",
    "            # --- Рисуем ключевые точки ---\n",
    "            if result.multi_hand_landmarks:\n",
    "                for hand_landmarks in result.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        frame,\n",
    "                        hand_landmarks,\n",
    "                        mp_hands.HAND_CONNECTIONS\n",
    "                    )\n",
    "\n",
    "            # --- Текст аннотаций ---\n",
    "            y_offset = START_Y\n",
    "            for annot_name, classes in annotators.items():\n",
    "                cls = classes[i] if i < len(classes) else -1\n",
    "                cls_text = class_map_cv2.get(int(cls), f\"Class {cls}\")\n",
    "                text = f\"{annot_name}: {cls_text}\"\n",
    "\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    text,\n",
    "                    (X_POS, y_offset),\n",
    "                    FONT,\n",
    "                    FONT_SCALE,\n",
    "                    FONT_COLOR,\n",
    "                    FONT_THICKNESS,\n",
    "                    cv2.LINE_AA\n",
    "                )\n",
    "                y_offset += LINE_HEIGHT\n",
    "\n",
    "            writer.write(frame)\n",
    "\n",
    "    writer.release()\n",
    "    cap.release()\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "507f15fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\0_moydadir\\MII_lab_10_train_model\\project\\venv3.12\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохранено: d:\\0_moydadir\\MII_lab_10_train_model\\project\\Video_with_annotations\\2020-06-26_21-26-56_camera104_annotated.mp4\n"
     ]
    }
   ],
   "source": [
    "dataset_n = \"DataSet4\"\n",
    "# video_name = \"2020-07-09_04-10-08_camera101.mp4\"\n",
    "video_name = \"2020-06-26_21-26-56_camera104.mp4\"\n",
    "\n",
    "# video_path = os.path.join(dataset_folder_path, dataset_n, \"Videos\", \"2020-06-26_18-28-10_camera102.mp4\")\n",
    "video_path = os.path.join(dataset_folder_path, dataset_n, \"Videos\", video_name)\n",
    "annotations_path = os.path.join(dataset_folder_path, dataset_n, \"Annotations\")\n",
    "output_folder = os.path.join(current_dir_code, \"Video_with_annotations\")\n",
    "\n",
    "out = visualize_annotations(video_path, annotations_path, output_folder, class_map=class_map_cv2)\n",
    "print(\"Сохранено:\", out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c31ba95",
   "metadata": {},
   "source": [
    "Написан код для визуализации аннотаций"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1153e66b",
   "metadata": {},
   "source": [
    "3. Преобразование данных к формату таблицы:\n",
    "    - Каждая строка = кадр, колонки = X, Y, Z координаты 21 точки для каждой руки + метка шага.\n",
    "    - Рассчитать centroid для каждой руки и нормализовать все точки относительно него (как в статье).\n",
    "    - Рассмотреть добавление производных признаков:\n",
    "        1) Относительные расстояния между ключевыми точками (межфаланговые, ладонь → пальцы).\n",
    "        2) Углы суставов.\n",
    "        3) Темпоральные признаки (разность координат по времени, скорость движения точек)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "152a2258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _landmarks_to_array(hand_landmarks, w, h):\n",
    "    \"\"\"Возвращает (21,3) массив x(px), y(px), z(relative). Если hand_landmarks is None -> None\"\"\"\n",
    "    if hand_landmarks is None:\n",
    "        return None\n",
    "    # Инициализация массива под 21 точку (x, y, z)\n",
    "    arr = np.zeros((21, 3), dtype=float)\n",
    "    # Проходим по всем 21 landmark\n",
    "    for i, lm in enumerate(hand_landmarks.landmark):\n",
    "        # Нормализованные координаты [0,1] пиксели\n",
    "        arr[i, 0] = lm.x * w\n",
    "        arr[i, 1] = lm.y * h\n",
    "\n",
    "        # Z оставляем как есть (относительная глубина)\n",
    "        arr[i, 2] = lm.z\n",
    "    return arr\n",
    "\n",
    "def _centroid(coords):\n",
    "    \"\"\"coords: (21,2) -> (cx,cy) ; если coords содержит NaN, игнорируем их\"\"\"\n",
    "    if coords is None:\n",
    "        return (np.nan, np.nan)\n",
    "    # Валидные точки — где x не NaN\n",
    "    valid = ~np.isnan(coords[:, 0])\n",
    "    # Если нет ни одной валидной точки\n",
    "    if not valid.any():\n",
    "        return (np.nan, np.nan)\n",
    "    # Среднее по валидным точкам\n",
    "    cx = np.nanmean(coords[valid, 0])  # TODO: почему здесь nanmean, если мы уже отфильтровали валидные?\n",
    "    cy = np.nanmean(coords[valid, 1])\n",
    "    return (cx, cy)\n",
    "\n",
    "def _hand_scale(coords, centroid):\n",
    "    \"\"\"Оценивает масштаб руки как максимальное расстояние\n",
    "    от центроида до любой ключевой точки\"\"\"\n",
    "    # Если данных нет — масштаб нейтральный\n",
    "    if coords is None:\n",
    "        return 1.0\n",
    "    # Векторы от центроида к каждой точке\n",
    "    vecs = coords[:, :2] - np.array(centroid)[None, :]\n",
    "    # Евклидовы расстояния\n",
    "    dists = np.linalg.norm(vecs, axis=1)\n",
    "    # Если все расстояния NaN\n",
    "    if np.all(np.isnan(dists)):\n",
    "        return 1.0\n",
    "    maxd = np.nanmax(dists)\n",
    "    # Защита от деления на 0\n",
    "    return float(maxd) if maxd > 1e-6 else 1.0\n",
    "\n",
    "def _angle_deg(a, b, c):\n",
    "    \"\"\"Угол в градусах в точке b между векторами ba и bc (a-b-c)\"\"\"\n",
    "    a = np.array(a, dtype=float)\n",
    "    b = np.array(b, dtype=float)\n",
    "    c = np.array(c, dtype=float)\n",
    "    # Векторы ba и bc\n",
    "    v1 = a - b\n",
    "    v2 = c - b\n",
    "    n1 = np.linalg.norm(v1)\n",
    "    n2 = np.linalg.norm(v2)\n",
    "    # Защита от нулевой длины\n",
    "    if n1 < 1e-8 or n2 < 1e-8:\n",
    "        return np.nan\n",
    "    # Косинус угла\n",
    "    cosang = np.dot(v1, v2) / (n1 * n2)\n",
    "    # Числовая стабильность\n",
    "    cosang = float(np.clip(cosang, -1.0, 1.0))\n",
    "    # Угол в градусах\n",
    "    ang = math.degrees(math.acos(cosang))\n",
    "    return ang\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# Если обработка многопоточная, нужно создавать отдельный объект mp для каждого потока\n",
    "def create_hands_processor():\n",
    "    \"\"\"Создает и возвращает объект MediaPipe Hands с заданными параметрами\"\"\"\n",
    "    return mp.solutions.hands.Hands(\n",
    "        static_image_mode=False,\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01447963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_time_and_label(\n",
    "    frame_idx: int,\n",
    "    fps: float,\n",
    "    ann_times_ms: np.ndarray,\n",
    "    ann_codes: np.ndarray,\n",
    "    ann_df: pd.DataFrame\n",
    ") -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Сопоставляет кадр видео с ближайшей аннотацией.\n",
    "    \"\"\"\n",
    "\n",
    "    # время текущего кадра в миллисекундах\n",
    "    frame_time_ms = (frame_idx / fps) * 1000.0\n",
    "\n",
    "    # индекс ближайшей аннотации\n",
    "    idx = int(np.argmin(np.abs(ann_times_ms - frame_time_ms)))\n",
    "\n",
    "    movement_code = float(ann_codes[idx])\n",
    "    is_washing = ann_df.iloc[idx].get(\"is_washing\", np.nan)\n",
    "\n",
    "    return frame_time_ms, movement_code, is_washing\n",
    "\n",
    "def extract_hands_arrays(\n",
    "    mp_result,\n",
    "    frame_w: int,\n",
    "    frame_h: int\n",
    ") -> Dict[str, Optional[np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Возвращает словарь:\n",
    "        {\n",
    "            \"left\":  np.ndarray(21,3) | None,\n",
    "            \"right\": np.ndarray(21,3) | None\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    hands = {\"left\": None, \"right\": None}\n",
    "\n",
    "    if not mp_result.multi_hand_landmarks:\n",
    "        return hands\n",
    "\n",
    "    handedness = mp_result.multi_handedness or []\n",
    "\n",
    "    for i, hand_lm in enumerate(mp_result.multi_hand_landmarks):\n",
    "        arr = _landmarks_to_array(hand_lm, frame_w, frame_h)\n",
    "\n",
    "        # определяем сторону\n",
    "        side = None\n",
    "        if i < len(handedness):\n",
    "            side = handedness[i].classification[0].label.lower()\n",
    "\n",
    "        # fallback по X\n",
    "        if side is None:\n",
    "            side = \"left\" if np.nanmean(arr[:, 0]) < frame_w / 2 else \"right\"\n",
    "\n",
    "        hands[side] = arr\n",
    "\n",
    "    return hands\n",
    "\n",
    "def build_hand_features(\n",
    "    arr: Optional[np.ndarray],\n",
    "    hand_label: str,\n",
    "    normalize: bool\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Формирует все признаки для одной руки (L или R).\"\"\"\n",
    "\n",
    "    rec = {}\n",
    "\n",
    "    # если руки нет — NaN\n",
    "    if arr is None:\n",
    "        for i in range(21):\n",
    "            rec[f\"{hand_label}_x_{i}\"] = np.nan\n",
    "            rec[f\"{hand_label}_y_{i}\"] = np.nan\n",
    "            rec[f\"{hand_label}_z_{i}\"] = np.nan\n",
    "        rec[f\"{hand_label}_cx\"] = np.nan\n",
    "        rec[f\"{hand_label}_cy\"] = np.nan\n",
    "        rec[f\"{hand_label}_scale\"] = np.nan\n",
    "        return rec\n",
    "\n",
    "    # сырые координаты\n",
    "    for i in range(21):\n",
    "        rec[f\"{hand_label}_x_{i}\"] = float(arr[i, 0])\n",
    "        rec[f\"{hand_label}_y_{i}\"] = float(arr[i, 1])\n",
    "        rec[f\"{hand_label}_z_{i}\"] = float(arr[i, 2])\n",
    "\n",
    "    # центроид и масштаб\n",
    "    cx, cy = _centroid(arr[:, :2])\n",
    "    scale = _hand_scale(arr, (cx, cy))\n",
    "    rec[f\"{hand_label}_cx\"] = float(cx)\n",
    "    rec[f\"{hand_label}_cy\"] = float(cy)\n",
    "    rec[f\"{hand_label}_scale\"] = float(scale)\n",
    "\n",
    "    # нормализация\n",
    "    if normalize:\n",
    "        for i in range(21):\n",
    "            rec[f\"{hand_label}_nx_{i}\"] = float((arr[i, 0] - cx) / scale)\n",
    "            rec[f\"{hand_label}_ny_{i}\"] = float((arr[i, 1] - cy) / scale)\n",
    "\n",
    "    # расстояния wrist → fingertips\n",
    "    wrist = arr[0, :2]\n",
    "    for j, idx in enumerate([4, 8, 12, 16, 20]):\n",
    "        rec[f\"{hand_label}_tip{j}_wrist_dist\"] = float(\n",
    "            np.linalg.norm(arr[idx, :2] - wrist)\n",
    "        )\n",
    "\n",
    "    # углы суставов\n",
    "    finger_joints = {\n",
    "        \"index\": (5, 6, 7),\n",
    "        \"middle\": (9, 10, 11),\n",
    "        \"ring\": (13, 14, 15),\n",
    "        \"pinky\": (17, 18, 19),\n",
    "        \"thumb\": (1, 2, 3)\n",
    "    }\n",
    "\n",
    "    for name, (a, b, c) in finger_joints.items():\n",
    "        rec[f\"{hand_label}_angle_{name}_pip\"] = float(\n",
    "            _angle_deg(arr[a, :2], arr[b, :2], arr[c, :2])\n",
    "        )\n",
    "\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e24f643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_landmarks_table(\n",
    "    video_path: str,\n",
    "    ann_df: pd.DataFrame,\n",
    "    dataset: Optional[str] = None,\n",
    "    annotator: Optional[str] = None,\n",
    "    normalize: bool = True,\n",
    "    compute_derivatives: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Строит табличный датасет по видео и аннотациям.\"\"\"\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    frame_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    ann_times = ann_df[\"frame_time\"].to_numpy(float)\n",
    "    ann_codes = ann_df[\"movement_code\"].to_numpy(float)\n",
    "\n",
    "    hands_proc = create_hands_processor()\n",
    "    rows = []\n",
    "\n",
    "    for frame_idx in range(total_frames):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_time, movement_code, is_washing = get_frame_time_and_label(\n",
    "            frame_idx, fps, ann_times, ann_codes, ann_df\n",
    "        )\n",
    "\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        res = hands_proc.process(rgb)\n",
    "\n",
    "        hands = extract_hands_arrays(res, frame_w, frame_h)\n",
    "\n",
    "        rec = {\n",
    "            \"frame_idx\": frame_idx,\n",
    "            \"frame_time\": frame_time,\n",
    "            \"movement_code\": movement_code,\n",
    "            \"is_washing\": is_washing,\n",
    "            \"dataset\": dataset,\n",
    "            \"annotator\": annotator,\n",
    "            \"video\": os.path.basename(video_path)\n",
    "        }\n",
    "\n",
    "        rec.update(build_hand_features(hands[\"left\"], \"L\", normalize))\n",
    "        rec.update(build_hand_features(hands[\"right\"], \"R\", normalize))\n",
    "\n",
    "        rows.append(rec)\n",
    "\n",
    "    hands_proc.close()\n",
    "    cap.release()\n",
    "\n",
    "    df_out = pd.DataFrame(rows)\n",
    "\n",
    "    # скорости\n",
    "    if compute_derivatives and normalize:\n",
    "        dt = 1.0 / fps\n",
    "        for h in (\"L\", \"R\"):\n",
    "            for i in range(21):\n",
    "                df_out[f\"{h}_nvx_{i}\"] = df_out[f\"{h}_nx_{i}\"].diff().fillna(0) / dt  # normalize velocity x\n",
    "                df_out[f\"{h}_nvy_{i}\"] = df_out[f\"{h}_ny_{i}\"].diff().fillna(0) / dt\n",
    "\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff4b58b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing tasks: 100%|██████████| 1000/1000 [00:00<00:00, 45747.89it/s]\n",
      "Create key unique tasks: 100%|██████████| 1000/1000 [00:00<?, ?it/s]\n",
      "Processing sequential:   0%|          | 0/2 [00:00<?, ?it/s]d:\\0_moydadir\\MII_lab_10_train_model\\project\\venv3.12\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "Processing sequential:  50%|█████     | 1/2 [00:12<00:12, 12.60s/it]d:\\0_moydadir\\MII_lab_10_train_model\\project\\venv3.12\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "Processing sequential: 100%|██████████| 2/2 [00:24<00:00, 12.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "ok    2\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_root = os.path.join(current_dir_code, \"landmarks_parquet_test\")   # куда сохранять результаты\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "# Число процессов (None -> автоматически cpu_count()-1)\n",
    "import multiprocessing\n",
    "DEFAULT_WORKERS = max(1, multiprocessing.cpu_count() - 1)\n",
    "\n",
    "# ----- ВСПОМОГАТЕЛЬНЫЕ ФУНКЦИИ -----\n",
    "def _mp_worker(task):\n",
    "    \"\"\"\n",
    "    worker выполняет обработку одной аннотации.\n",
    "    task: dict с ключами:\n",
    "      - video_csv_name (str): '2020-06-26_18-28-10_camera102.csv'\n",
    "      - dataset (str)\n",
    "      - annotator (str)\n",
    "      - dataset_folder_path (str)\n",
    "      - output_root (str)\n",
    "    Возвращает dict с полями status, message, out_path (если успешно).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        video_csv_name = task[\"video_csv_name\"]\n",
    "        dataset = task[\"dataset\"]\n",
    "        annotator = task[\"annotator\"]\n",
    "        dataset_folder_path = task[\"dataset_folder_path\"]\n",
    "        output_root = task[\"output_root\"]\n",
    "\n",
    "        # пути\n",
    "        ds_path = os.path.join(dataset_folder_path, dataset)\n",
    "        ann_path = os.path.join(ds_path, \"Annotations\", annotator, video_csv_name)\n",
    "        video_base = os.path.splitext(video_csv_name)[0]\n",
    "        video_mp4_name = video_base + \".mp4\"\n",
    "        video_path = os.path.join(ds_path, \"Videos\", video_mp4_name)\n",
    "\n",
    "        if not os.path.isfile(ann_path):\n",
    "            return {\"status\": \"missing_annotation\", \"message\": f\"Аннотация не найдена: {ann_path}\", \"task\": task}\n",
    "        if not os.path.isfile(video_path):\n",
    "            return {\"status\": \"missing_video\", \"message\": f\"Видео не найдено: {video_path}\", \"task\": task}\n",
    "\n",
    "        # Папка вывода для dataset/annotator\n",
    "        out_dir = os.path.join(output_root, dataset, annotator)\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        out_fname = f\"{video_base}_landmarks.parquet\"\n",
    "        out_path = os.path.join(out_dir, out_fname)\n",
    "\n",
    "        # Если уже есть — пропускаем (resume)\n",
    "        if os.path.exists(out_path):\n",
    "            return {\"status\": \"skipped\", \"message\": \"Уже обработан\", \"out_path\": out_path, \"task\": task}\n",
    "\n",
    "        # читаем аннотацию\n",
    "        ann_df = pd.read_csv(ann_path)\n",
    "\n",
    "        # Запуск извлечения\n",
    "        df_out = extract_landmarks_table(\n",
    "            video_path=video_path,\n",
    "            ann_df=ann_df,\n",
    "            dataset=dataset,\n",
    "            annotator=annotator,\n",
    "            normalize=True,\n",
    "            compute_derivatives=True\n",
    "        )\n",
    "\n",
    "        # Сохранение\n",
    "        df_out.to_parquet(out_path)\n",
    "        return {\"status\": \"ok\", \"message\": \"Saved\", \"out_path\": out_path, \"task\": task}\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": str(e), \"task\": task}\n",
    "\n",
    "\n",
    "def process_all_annotations(df, dataset_folder_path, output_root, n_workers=None):\n",
    "    \"\"\"\n",
    "    df: DataFrame с колонками ['frame_time','is_washing','movement_code','dataset','annotator','video']\n",
    "    dataset_folder_path: путь к корню DataSet\n",
    "    output_root: куда сохранять parquet\n",
    "    n_workers: число процессов\n",
    "    \"\"\"\n",
    "    if n_workers is None:\n",
    "        n_workers = DEFAULT_WORKERS\n",
    "\n",
    "    # Убираем дубликаты на уровне (dataset, annotator, video)\n",
    "    tasks = []\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Preparing tasks\"):\n",
    "        dataset = str(row[\"dataset\"])\n",
    "        annotator = str(row[\"annotator\"])\n",
    "        video_csv_name = str(row[\"video\"])\n",
    "        # игнорируем строки без необходимых полей\n",
    "        if not video_csv_name:\n",
    "            continue\n",
    "        tasks.append({\n",
    "            \"dataset\": dataset,\n",
    "            \"annotator\": annotator,\n",
    "            \"video_csv_name\": video_csv_name,\n",
    "            \"dataset_folder_path\": dataset_folder_path,\n",
    "            \"output_root\": output_root\n",
    "        })\n",
    "\n",
    "    # Уникализируем\n",
    "    unique_tasks = []\n",
    "    seen = set()\n",
    "    for t in tqdm(tasks, desc=\"Create key unique tasks\"):\n",
    "        key = (t[\"dataset\"], t[\"annotator\"], t[\"video_csv_name\"])\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        unique_tasks.append(t)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for task in tqdm(unique_tasks, desc=\"Processing sequential\"):\n",
    "        res = _mp_worker(task)\n",
    "        results.append(res)\n",
    "\n",
    "    # # Параллельное выполнение\n",
    "    # with ProcessPoolExecutor(max_workers=n_workers) as ex:\n",
    "    #     futures = {ex.submit(_mp_worker, task): task for task in unique_tasks}\n",
    "    #     for fut in tqdm(as_completed(futures), total=len(futures), desc=\"Processing\"):\n",
    "    #         res = fut.result()\n",
    "    #         results.append(res)\n",
    "\n",
    "    # Сводка\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# вызвать процессинг\n",
    "summary_df = process_all_annotations(df, dataset_folder_path, output_root)\n",
    "print(summary_df.status.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8979b9e3",
   "metadata": {},
   "source": [
    "Написан код для формирования конвертации данных из видео в табличный формат. Данные сохраняются в файл с расширением parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1489331",
   "metadata": {},
   "source": [
    "# 2. Предварительная обработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430ef8fd",
   "metadata": {},
   "source": [
    "1. Проверка и обработка пропусков:\n",
    "    - Удаление или интерполяция отсутствующих точек.\n",
    "    - Проверка на некорректные координаты (например, выходящие за пределы кадра)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e6cc01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ac43b3b",
   "metadata": {},
   "source": [
    "Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9280409",
   "metadata": {},
   "source": [
    "2. Описательная статистика:\n",
    "    Среднее, медиана, std, min/max для координат и производных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cee7f30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af385efa",
   "metadata": {},
   "source": [
    "Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9312a5fa",
   "metadata": {},
   "source": [
    "3. Визуализация распределений с учетом шкал измерений:\n",
    "    -\tдля дискретных значений (класс) – с помощью диаграмм частотности,\n",
    "    -\tдля непрерывных – с помощью графиков функции плотности распределения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9a07f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d79f76d",
   "metadata": {},
   "source": [
    "Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a81ede",
   "metadata": {},
   "source": [
    "4. Проверка гипотез:\n",
    "    - нормальное (логнормальное) распределение непрерывных признаков (Shapiro–Wilk..).\n",
    "    - Корреляция или независимость между признаками (Pearson/Spearman)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270f98cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1fc5640",
   "metadata": {},
   "source": [
    "Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c040720",
   "metadata": {},
   "source": [
    "5. Нормализация признаков:\n",
    "    - Центрирование относительно centroid.\n",
    "    - Масштабирование признаков (StandardScaler или MinMaxScaler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7389c045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04fad8b1",
   "metadata": {},
   "source": [
    "Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d6674c",
   "metadata": {},
   "source": [
    "6. Снижение размерности:\n",
    "    - PCA/tSNE\n",
    "    - Проверить возможность понижения размерности за счет выбора наиболее информативных признаков (часть признаков отсекаем, часть оставляем). \n",
    "    - Вероятно, все признаки важны, но проверка полезна."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fafde0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d09133f3",
   "metadata": {},
   "source": [
    "Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8001c6da",
   "metadata": {},
   "source": [
    "7. Подготовка к обучению:\n",
    "    Split train/test (80/20) + cross-validation для подбора гиперпараметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8f3b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "819188c8",
   "metadata": {},
   "source": [
    "Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90f6227",
   "metadata": {},
   "source": [
    "# 3. Построение и тестирование моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c235e7",
   "metadata": {},
   "source": [
    "1. Модели многоклассовой классификации:\n",
    "    - Logistic Regression (использовали в статье)\n",
    "    - SVM (использовали в статье)\n",
    "    - Random Forest (использовали в статье)\n",
    "    - Decision Tree\n",
    "    - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee5523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d541956",
   "metadata": {},
   "source": [
    "Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a129c9",
   "metadata": {},
   "source": [
    "2. Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3c8471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9b0354c",
   "metadata": {},
   "source": [
    "Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6930e84f",
   "metadata": {},
   "source": [
    "3. Метрики оценки:\n",
    "    - Accuracy, Precision, Recall, F1-score (по классам).\n",
    "    - Confusion matrix.\n",
    "    - ROC/PR-кривые для многоклассовой задачи.\n",
    "    - Сравнение времени предсказания и использования памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05308027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5be73686",
   "metadata": {},
   "source": [
    "Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526c9afa",
   "metadata": {},
   "source": [
    "4. Реализация предсказаний на видео с рекордера (для LR или выбранной модели)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931a3b33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "241c1ecf",
   "metadata": {},
   "source": [
    "Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a72ebfb",
   "metadata": {},
   "source": [
    "5. Анализ ошибок:\n",
    "    Выявление шагов с наибольшей путаницей (например, 2.1 vs 5.2). (взято из статьи)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de5c9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dd483d4",
   "metadata": {},
   "source": [
    "6. Выводы:\n",
    "    - Оптимальная модель по точности/скорости/ресурсам.\n",
    "    - Возможные улучшения (дополнительные признаки, расширение dataset)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
